{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week3-Lab3.ipynb","provenance":[{"file_id":"1FkxlYJVzEjwv9p4h4FziLXwSMVqXlaOq","timestamp":1578034396075}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9xAiOsjBZtU0","colab_type":"text"},"source":["# **GluonCV Demo: Instance Segmentation using Mask R-CNN**"]},{"cell_type":"code","metadata":{"id":"lksCrNxqSfoe","colab_type":"code","colab":{}},"source":["# 1. Install MXNet and GluonCV, load Python Packages\n","\n","! pip install -q mxnet gluoncv --progress-bar off\n","from gluoncv import model_zoo, data, utils\n","from matplotlib import pyplot as plt\n","\n","# 2. Upload an Image File\n","# We can upload multiple image files at the same time, but try upload one image file only.\n","\n","from google.colab import files\n","uploaded = files.upload()\n","\n","# 3. Load Mask R-CNN Pre-trained Model\n","# We use Mask R-CNN model trained on Microsoft COCO dataset\n","# Other available models: https://gluon-cv.mxnet.io/model_zoo/segmentation.html\n","\n","MaskRCNN = model_zoo.get_model('mask_rcnn_resnet50_v1b_coco', pretrained=True)\n","\n","# 4. Print out the Class Names supported by Mask R-CNN\n","print('Total number of classes recognized by Mask R-CNN:', len(MaskRCNN.classes))\n","print('The classes are:', MaskRCNN.classes)\n","\n","# 5. Transform the Image File to Suitable Format\n","# At step 2 we can upload multiple image files at the same time, but here we only use the first image file.\n","# Transformation default: short side = 600 pixels, long side <= 1000 pixels, keep aspect ratio.\n","# new_data: Numerical data that will be passed to Faster R-CNN for object detection\n","# new_image: Newly transformed image according to Faster R-CNN requirement\n","\n","new_data, new_image = data.transforms.presets.rcnn.load_test(list(uploaded.keys())[0])\n","\n","# 6. Apply Mask R-CNN to do Instance Segmentation\n","# box_ids: The class ID of bounding box (which kind of object is detected)\n","# scores: The probability that the bounding box contains the detected object\n","# bboxes: Bounding box coordinates\n","# masks: Masks showing which pixel corresponds to which class\n","\n","box_ids, scores, bboxes, masks = MaskRCNN(new_data)\n","\n","# 7. Display the Instance Segmentation Result\n","# Expand instance segmentation mask to full image size\n","width, height = new_image.shape[1], new_image.shape[0]\n","new_masks, _ = utils.viz.expand_mask(masks[0], bboxes[0], (width, height), scores[0])\n","new_image = utils.viz.plot_mask(new_image, new_masks)\n","fig = plt.figure(figsize=(10, 10))\n","ax = fig.add_subplot(1, 1, 1)\n","\n","# Threshold = 0.5 means we only display those bounding boxes with scores >= 0.5\n","ax = utils.viz.plot_bbox(new_image, bboxes[0], scores[0], box_ids[0], class_names=MaskRCNN.classes, thresh=0.5, ax=ax)\n","plt.show()\n","\n","# 8. Print out the Numerical Result of Instance Segmentation\n","for i in range(len(box_ids[0])):\n","    if box_ids[0][i] != -1 and scores[0][i].asscalar() >= 0.5:\n","        print('Class =', MaskRCNN.classes[int(box_ids[0][i].asscalar())], ' Bounding Box =', bboxes[0][i].asnumpy(), ' Score =', scores[0][i].asscalar())"],"execution_count":0,"outputs":[]}]}